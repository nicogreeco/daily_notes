{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ab114ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.daily_notes_processor import DailyNotesProcessor\n",
    "from src.config import Config\n",
    "from src.audio_processor import AudioProcessor\n",
    "from src.note_generator import NoteGenerator\n",
    "from src.timeline_generator import TimelineGenerator\n",
    "from src.todo_extractor import TodoExtractor\n",
    "from src.todo_manager import TodoManager\n",
    "\n",
    "from datetime import datetime\n",
    "from faster_whisper import WhisperModel, BatchedInferencePipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41965cb",
   "metadata": {},
   "source": [
    "## Step by Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd00ce96",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config('config.yaml')\n",
    "config_gpt = Config('config.yaml')\n",
    "config_deep = Config('config_debug.yaml')\n",
    "audio_processor = AudioProcessor(config_gpt)\n",
    "\n",
    "# No need to pass API keys - they're handled in the constructors\n",
    "note_generator_gpt = NoteGenerator(\n",
    "    config_gpt,\n",
    "    model=config_gpt.model,\n",
    "    temperature=config_gpt.temperature\n",
    ")\n",
    "\n",
    "note_generator_deep = NoteGenerator(\n",
    "    config_deep,\n",
    "    model=config_deep.model,\n",
    "    temperature=config_deep.temperature\n",
    ")\n",
    "\n",
    "\n",
    "# Initialize TodoExtractor\n",
    "todo_extractor_gpt = TodoExtractor(\n",
    "    config_gpt,\n",
    "    note_generator_gpt,\n",
    "    audio_processor\n",
    ")\n",
    "\n",
    "todo_extractor_deep = TodoExtractor(\n",
    "    config_deep,\n",
    "    note_generator_deep,\n",
    "    audio_processor\n",
    ")\n",
    "\n",
    "todo_manager_gpt = TodoManager(config_gpt, temperature=config_gpt.temperature)\n",
    "todo_manager_deep = TodoManager(config_deep, temperature=config_deep.temperature)\n",
    "\n",
    "audio_processor = AudioProcessor(config_gpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f16c883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('c:/Users/nicco/OneDrive/Documenti/Obsidian/daily_notes/AudioInbox/Daily_Log_25-06-2025.mp3')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supported_formats = config.config_data['audio']['supported_formats']\n",
    "audio_files = []\n",
    "\n",
    "for format_ext in supported_formats:\n",
    "    audio_files.extend(config.audio_input_path.glob(f\"*{format_ext}\"))\n",
    "    \n",
    "sorted(audio_files)\n",
    "audio_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89fadafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Processing: Daily_Log_25-06-2025.mp3\n",
      "==================================================\n",
      "Date extracted from filename: 2025-06-25\n",
      "Transcription completed (1094 chars)\n"
     ]
    }
   ],
   "source": [
    "audio_path = audio_files[0]\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Processing: {audio_path.name}\")\n",
    "print(f\"{'='*50}\")\n",
    "\n",
    "# Extract date from filename if possible\n",
    "date_str = todo_extractor_gpt.extract_date_from_filename(audio_path.name)\n",
    "if date_str:\n",
    "    print(f\"Date extracted from filename: {date_str}\")\n",
    "else:\n",
    "    date_str = datetime.now().strftime('%Y-%m-%d')\n",
    "    print(f\"Using current date: {date_str}\")\n",
    "\n",
    "# 1. Transcribe audio\n",
    "# transcript_data = audio_processor.transcribe(audio_path)\n",
    "transcript_data = { 'text' :\" so today I worked on my main project so silencing and apart from that I continued working with the plotting function the plotting functions for plotting and inspecting data from diffusion runs I make it work I made it work with how the data are saved  I return in the function to sample from the diffusion model so it returns the sampled sequence and dictionary of data this dictionary has several entries and each entry is a stack tensor of probabilities for  all the steps rather than a list of tens of probability for each step and I had to make the functions work with this and now they are working I also had some smaller features like printing metadata when plotting the interactive plot that's working I made some more small changes into the script  I made some more small changes into into the script for visualizing and for saving datas and I prepared everything for the PR I made the PR then I also reviewed the PR that Ishan made  Then I also continued working on updating the conference post, writing down some comments on some plots I showed last Thursday. Nothing more than that.\"}\n",
    "print(f\"Transcription completed ({len(transcript_data['text'])} chars)\")\n",
    "\n",
    "# 2. Get available projects\n",
    "available_projects = config.get_available_projects()\n",
    "# print(f\"Available projects: {', '.join(available_projects)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c1a4ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved transcript: c:\\Users\\nicco\\OneDrive\\Documenti\\Obsidian\\Vault\\1. Projects\\Daily Notes\\transcripts\\2025-06-25_Saliency_transcript_145242.md\n",
      "Created daily note for project 'Saliency': c:\\Users\\nicco\\OneDrive\\Documenti\\Obsidian\\Vault\\1. Projects\\Daily Notes\\2025-06-25_Saliency_gpt_debug.md\n",
      "Checking for todo items in transcript...\n",
      "No todo items found in transcript.\n"
     ]
    }
   ],
   "source": [
    "audio_filename=audio_files[0].name\n",
    "output_path=config.daily_notes_path\n",
    "\n",
    "# Generate content from transcript\n",
    "content_gpt, response_gpt   = note_generator_gpt.generate_note_content(transcript_data['text'], available_projects)\n",
    "\n",
    "# Extract detected project\n",
    "detected_project = content_gpt.get('project', 'Unknown')\n",
    "\n",
    "# Prepare template variables\n",
    "now = datetime.now()\n",
    "if date_str is None:\n",
    "    date_str = now.strftime('%Y-%m-%d')\n",
    "\n",
    "template_vars = {\n",
    "    'date': date_str,\n",
    "    'project_name': detected_project,\n",
    "    'audio_filename': audio_filename,\n",
    "    'timestamp': now.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'summary': content_gpt['summary'],\n",
    "    'completed': content_gpt['completed'],\n",
    "    'blockers': content_gpt['blockers'],\n",
    "    'next_steps': content_gpt['next_steps'],\n",
    "    'thoughts': content_gpt['thoughts'],\n",
    "    'transcript_link': \"\"  # Default empty\n",
    "}\n",
    "\n",
    "# Save transcript if enabled\n",
    "if config.save_transcript:\n",
    "    transcript_path = note_generator_gpt._save_transcript(\n",
    "        transcript_data['text'],\n",
    "        date_str,\n",
    "        detected_project,\n",
    "        output_path\n",
    "    )\n",
    "    # Create relative path for the link\n",
    "    relative_path = transcript_path.name if transcript_path.parent == output_path else f\"{config.transcript_folder}/{transcript_path.name}\"\n",
    "    template_vars['transcript_link'] = f\"## üìù Full Transcript\\n[View complete transcript]({relative_path})\\n\"\n",
    "\n",
    "# Fill template\n",
    "note_content = note_generator_gpt.get_daily_note_template().format(**template_vars)\n",
    "\n",
    "# Create output file\n",
    "daily_note_path = output_path / f\"{date_str}_{detected_project}_gpt_debug.md\"\n",
    "\n",
    "# Handle existing file\n",
    "if daily_note_path.exists():\n",
    "    timestamp_suffix = now.strftime('%H%M%S')\n",
    "    daily_note_path = output_path / f\"{date_str}_{detected_project}_{timestamp_suffix}.md\"\n",
    "    print(f\"Daily note exists, creating: {daily_note_path.name}\")\n",
    "\n",
    "# Write file\n",
    "with open(daily_note_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(note_content)\n",
    "    \n",
    "print(f\"Created daily note for project '{detected_project}': {daily_note_path}\")\n",
    "\n",
    "# Extract and add todo items\n",
    "print(\"Checking for todo items in transcript...\")\n",
    "todo_items = note_generator_gpt.todo_manager.extract_todos(transcript_data['text'], detected_project)\n",
    "\n",
    "if todo_items:\n",
    "    print(f\"Found {len(todo_items)} todo items.\")\n",
    "    note_generator_gpt.todo_manager.add_todos_to_project(detected_project, todo_items, date_str)\n",
    "else:\n",
    "    print(\"No todo items found in transcript.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80573227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'project': 'Saliency',\n",
       " 'summary': \"Today, I focused primarily on the Saliency project, enhancing the plotting functions used to inspect data from diffusion runs. I adapted the plotting functions to work with the updated data format, where the diffusion model's sampling function now returns a sampled sequence alongside a dictionary containing stacked tensors of probabilities for all steps, instead of a list of tensors per step. This required significant adjustments, which are now successfully implemented. Additionally, I added smaller features such as printing metadata on the interactive plots and made various improvements to the visualization and data-saving scripts. I prepared and submitted a pull request (PR) for these changes and reviewed a PR submitted by Ishan. Lastly, I continued updating the conference post by adding comments on plots presented last Thursday.\",\n",
       " 'completed': '- Adapted plotting functions to handle new data format with stacked tensors of probabilities for all diffusion steps\\n- Implemented metadata printing in interactive plots\\n- Made multiple small improvements to visualization and data-saving scripts\\n- Prepared and submitted a pull request for these changes\\n- Reviewed a pull request from Ishan\\n- Updated conference post with comments on previous plots',\n",
       " 'blockers': 'None mentioned',\n",
       " 'next_steps': 'Continue refining the conference post and possibly address feedback from the submitted PRs',\n",
       " 'thoughts': 'None mentioned'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1184ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"project\": \"Saliency\",\\n  \"summary\": \"Today, I focused primarily on the Saliency project, enhancing the plotting functions used to inspect data from diffusion runs. I adapted the plotting functions to work with the updated data format, where the diffusion model\\'s sampling function now returns a sampled sequence alongside a dictionary containing stacked tensors of probabilities for all steps, instead of a list of tensors per step. This required significant adjustments, which are now successfully implemented. Additionally, I added smaller features such as printing metadata on the interactive plots and made various improvements to the visualization and data-saving scripts. I prepared and submitted a pull request (PR) for these changes and reviewed a PR submitted by Ishan. Lastly, I continued updating the conference post by adding comments on plots presented last Thursday.\",\\n  \"completed\": \"- Adapted plotting functions to handle new data format with stacked tensors of probabilities for all diffusion steps\\\\n- Implemented metadata printing in interactive plots\\\\n- Made multiple small improvements to visualization and data-saving scripts\\\\n- Prepared and submitted a pull request for these changes\\\\n- Reviewed a pull request from Ishan\\\\n- Updated conference post with comments on previous plots\",\\n  \"blockers\": \"None mentioned\",\\n  \"next_steps\": \"Continue refining the conference post and possibly address feedback from the submitted PRs\",\\n  \"thoughts\": \"None mentioned\"\\n}'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_gpt.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ef01027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fallback: extracting content manually, JSON parsing failed\n",
      "Saved transcript: c:\\Users\\nicco\\OneDrive\\Documenti\\Obsidian\\Vault\\1. Projects\\Daily Notes\\transcripts\\2025-06-25_Saliency_transcript_145302.md\n",
      "Created daily note for project 'Saliency': c:\\Users\\nicco\\OneDrive\\Documenti\\Obsidian\\Vault\\1. Projects\\Daily Notes\\2025-06-25_Saliency_deep_debug.md\n",
      "Checking for todo items in transcript...\n",
      "No todo items found in transcript.\n"
     ]
    }
   ],
   "source": [
    "audio_filename=audio_files[0].name\n",
    "output_path=config.daily_notes_path\n",
    "\n",
    "# Generate content from transcript\n",
    "content_deep, response_deep = note_generator_deep.generate_note_content(transcript_data['text'], available_projects)\n",
    "\n",
    "# Extract detected project\n",
    "detected_project = content_deep.get('project', 'Unknown')\n",
    "\n",
    "# Prepare template variables\n",
    "now = datetime.now()\n",
    "if date_str is None:\n",
    "    date_str = now.strftime('%Y-%m-%d')\n",
    "\n",
    "template_vars = {\n",
    "    'date': date_str,\n",
    "    'project_name': detected_project,\n",
    "    'audio_filename': audio_filename,\n",
    "    'timestamp': now.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'summary': content_deep['summary'],\n",
    "    'completed': content_deep['completed'],\n",
    "    'blockers': content_deep['blockers'],\n",
    "    'next_steps': content_deep['next_steps'],\n",
    "    'thoughts': content_deep['thoughts'],\n",
    "    'transcript_link': \"\"  # Default empty\n",
    "}\n",
    "\n",
    "# Save transcript if enabled\n",
    "if config.save_transcript:\n",
    "    transcript_path = note_generator_deep._save_transcript(\n",
    "        transcript_data['text'],\n",
    "        date_str,\n",
    "        detected_project,\n",
    "        output_path\n",
    "    )\n",
    "    # Create relative path for the link\n",
    "    relative_path = transcript_path.name if transcript_path.parent == output_path else f\"{config.transcript_folder}/{transcript_path.name}\"\n",
    "    template_vars['transcript_link'] = f\"## üìù Full Transcript\\n[View complete transcript]({relative_path})\\n\"\n",
    "\n",
    "# Fill template\n",
    "note_content = note_generator_deep.get_daily_note_template().format(**template_vars)\n",
    "\n",
    "# Create output file\n",
    "daily_note_path = output_path / f\"{date_str}_{detected_project}_deep_debug.md\"\n",
    "\n",
    "# Handle existing file\n",
    "if daily_note_path.exists():\n",
    "    timestamp_suffix = now.strftime('%H%M%S')\n",
    "    daily_note_path = output_path / f\"{date_str}_{detected_project}_{timestamp_suffix}.md\"\n",
    "    print(f\"Daily note exists, creating: {daily_note_path.name}\")\n",
    "\n",
    "# Write file\n",
    "with open(daily_note_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(note_content)\n",
    "    \n",
    "print(f\"Created daily note for project '{detected_project}': {daily_note_path}\")\n",
    "\n",
    "# Extract and add todo items\n",
    "print(\"Checking for todo items in transcript...\")\n",
    "todo_items = note_generator_deep.todo_manager.extract_todos(transcript_data['text'], detected_project)\n",
    "\n",
    "if todo_items:\n",
    "    print(f\"Found {len(todo_items)} todo items.\")\n",
    "    note_generator_deep.todo_manager.add_todos_to_project(detected_project, todo_items, date_str)\n",
    "else:\n",
    "    print(\"No todo items found in transcript.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "138440cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'project': 'Saliency',\n",
       " 'summary': \"Today's work focused on the Saliency project, primarily improving plotting functions for inspecting diffusion model data. Key achievements include making the plotting functions work with the new data structure (stacked tensors instead of lists), adding metadata printing for interactive plots, and preparing a PR. Also reviewed a colleague's PR and continued updating a conference post with plot comments.\",\n",
       " 'completed': \"- Made plotting functions work with stacked tensor data structure (instead of list of tensors)  \\n- Added metadata printing feature for interactive plots  \\n- Made small changes to visualization/saving scripts  \\n- Prepared and submitted a PR  \\n- Reviewed Ishan's PR\",\n",
       " 'blockers': 'None mentioned',\n",
       " 'next_steps': 'None mentioned',\n",
       " 'thoughts': '- Conference post updates: Writing comments on plots shown last Thursday'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c79343e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n    \"project\": \"Saliency\",\\n    \"summary\": \"Today\\'s work focused on the Saliency project, primarily improving plotting functions for inspecting diffusion model data. Key achievements include making the plotting functions work with the new data structure (stacked tensors instead of lists), adding metadata printing for interactive plots, and preparing a PR. Also reviewed a colleague\\'s PR and continued updating a conference post with plot comments.\",\\n    \"completed\": \"- Made plotting functions work with stacked tensor data structure (instead of list of tensors)  \\n- Added metadata printing feature for interactive plots  \\n- Made small changes to visualization/saving scripts  \\n- Prepared and submitted a PR  \\n- Reviewed Ishan\\'s PR\",\\n    \"blockers\": \"None mentioned\",\\n    \"next_steps\": \"None mentioned\",\\n    \"thoughts\": \"- Conference post updates: Writing comments on plots shown last Thursday\"\\n}'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_deep.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36a28f3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('c:/Users/nicco/OneDrive/Documenti/Obsidian/daily_notes/AudioInbox/test_record.m4a')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supported_formats = config.config_data['audio']['supported_formats']\n",
    "audio_files = []\n",
    "\n",
    "for format_ext in supported_formats:\n",
    "    audio_files.extend(config.audio_input_path.glob(f\"*{format_ext}\"))\n",
    "    \n",
    "sorted(audio_files)\n",
    "audio_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25f06a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing: test_record.m4a\n",
      "‚úì Audio validation passed: Valid audio file: 155.0s\n",
      "Normalizing audio for optimal transcription...\n",
      "‚úì Audio normalized\n",
      "Starting transcription...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:58<00:00,  9.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Transcription completed\n",
      "Transcription completed (1241 chars)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "audio_path = audio_files[0]\n",
    "\n",
    "# 1. Transcribe audio\n",
    "transcript_data = audio_processor.transcribe(audio_path)\n",
    "print(f\"Transcription completed ({len(transcript_data['text'])} chars)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac1f8eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available projects: ENPICOM, Saliency\n",
      "ChatCompletion(id='chatcmpl-BeFtknkoH2DEpzvmZUkzjzkaKR9Jl', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='```json\\n{\\n  \"project\": \"Saliency\",\\n  \"summary\": \"- Today I worked on my main project, Palency, which I believe is a reference to Saliency.\\\\n- I continued conducting experiments to test the gradient flow on the prediction model over the input embeddings.\\\\n- I focused on debugging an issue from Friday that was causing zero gradient in certain regions of the antibody sequences.\\\\n- The problem was related to how sequences were fragmented by the anarchy sequence segment function.\\\\n- I discovered that some sequences weren\\'t properly segmented, particularly in the framework region 4.\\\\n- This segmentation issue was affecting the indexing and lists, leading to inaccurate results.\\\\n- I made adjustments to make the process resistant to incorrectly fragmented sequences.\\\\n- Despite the fixes, I suspect that some sequences may still not be properly fragmented, leading to noisy output plots.\\\\n- There is a possibility that some CTL regions are being misclassified as framework regions, impacting gradient distribution calculations.\\\\n- Overall, I believe I have resolved the main issue, but I need to implement the solution into the main script for further experiments.\",\\n  \"completed\": \"- Identified and resolved the issue with zero gradient in antibody sequences.\\\\n- Made the segmentation process resistant to incorrectly fragmented sequences.\",\\n  \"blockers\": \"- Some sequences may still not be properly fragmented, which could affect output plots.\\\\n- Need to implement the solution into the main script to run the experiment.\",\\n  \"next_steps\": \"- Correctly implement the segmentation solution into the main script.\\\\n- Continue running experiments to verify the accuracy of the gradient flow calculations.\",\\n  \"thoughts\": \"- I have a feeling that some CTL regions are being misclassified, which may affect the results.\\\\n- Overall, I am 99% confident that the solution will work correctly.\"\\n}\\n```', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1748933932, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_34a54ae93c', usage=CompletionUsage(completion_tokens=371, prompt_tokens=634, total_tokens=1005, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "Created daily note for project 'Saliency': c:\\Users\\nicco\\OneDrive\\Documenti\\Obsidian\\Vault\\1. Projects\\Daily Notes\\2025-06-03_Saliency.md\n",
      "‚úÖ Success! Note: 2025-06-03_Saliency.md\n"
     ]
    }
   ],
   "source": [
    "# 2. Get available projects\n",
    "available_projects = config.get_available_projects()\n",
    "print(f\"Available projects: {', '.join(available_projects)}\")\n",
    "\n",
    "# 3. Generate daily note with project detection\n",
    "note_path = note_generator.create_daily_note(\n",
    "    transcript_data=transcript_data,\n",
    "    available_projects=available_projects,\n",
    "    audio_filename=audio_path.name,\n",
    "    output_path=config.daily_notes_path\n",
    ")\n",
    "\n",
    "# 4. Delete audio file if configured\n",
    "if config.config_data['audio']['delete_after_processing']:\n",
    "    success = audio_processor.delete_audio_file(audio_path)\n",
    "    if not success:\n",
    "        print(f\"‚ö† Warning: Could not delete {audio_path.name}\")\n",
    "\n",
    "print(f\"‚úÖ Success! Note: {note_path.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae77a81",
   "metadata": {},
   "source": [
    "## Interactvie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c8d8e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Whisper model 'medium'...\n",
      "‚úì Whisper model loaded successfully\n",
      "Setup complete. Drop audio files in: c:\\Users\\nicco\\OneDrive\\Documenti\\Obsidian\\daily_notes\\AudioInbox\n"
     ]
    }
   ],
   "source": [
    "processor = DailyNotesProcessor('config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b07c6dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Daily Notes Processor - Interactive Mode\n",
      "==================================================\n",
      "\n",
      "Choose an option:\n",
      "1. üìÅ Scan for new audio files\n",
      "2. üé§ Record new voice note\n",
      "3. ‚öôÔ∏è  Configure audio device\n",
      "4. üìã Show current settings\n",
      "5. üìÖ Generate timeline\n",
      "6. üö™ Exit\n",
      "\n",
      "üé§ Recording Voice Note\n",
      "------------------------------\n",
      "\n",
      "üéôÔ∏è  Ready to record to: c:\\Users\\nicco\\OneDrive\\Documenti\\Obsidian\\daily_notes\\AudioInbox\n",
      "üî¥ Recording started using: System Default (Microphone (2- EDIFIER W830NB))\n",
      "Press SPACE to stop or Ctrl+C to cancel...\n",
      "\n",
      "‚èπÔ∏è  Stopping recording...\n",
      "‚úÖ Recording stopped! Duration: 245.18 seconds\n",
      "‚úÖ Audio saved: voice_note_20250603_172430.wav (21118.0 KB)\n",
      "\n",
      "‚úÖ Recording saved: voice_note_20250603_172430.wav\n",
      "\n",
      "üîÑ Processing voice_note_20250603_172430.wav...\n",
      "\n",
      "==================================================\n",
      "Processing: voice_note_20250603_172430.wav\n",
      "==================================================\n",
      "Transcribing: voice_note_20250603_172430.wav\n",
      "‚úì Audio validation passed: Valid audio file: 245.2s\n",
      "Normalizing audio for optimal transcription...\n",
      "‚úì Audio normalized\n",
      "Starting transcription...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicco\\OneDrive\\Documenti\\Obsidian\\.venv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: English\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 24517/24517 [02:40<00:00, 152.40frames/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Transcription completed\n",
      "Transcription completed (2239 chars)\n",
      "Available projects: ENPICOM, Saliency\n",
      "Daily note exists, creating: 2025-06-03_Saliency_173143.md\n",
      "Created daily note for project 'Saliency': c:\\Users\\nicco\\OneDrive\\Documenti\\Obsidian\\Vault\\1. Projects\\Daily Notes\\2025-06-03_Saliency_173143.md\n",
      "‚úÖ Success! Note: 2025-06-03_Saliency_173143.md\n",
      "‚úÖ Voice note processed successfully!\n",
      "\n",
      "Choose an option:\n",
      "1. üìÅ Scan for new audio files\n",
      "2. üé§ Record new voice note\n",
      "3. ‚öôÔ∏è  Configure audio device\n",
      "4. üìã Show current settings\n",
      "5. üìÖ Generate timeline\n",
      "6. üö™ Exit\n",
      "\n",
      "üé§ Recording Voice Note\n",
      "------------------------------\n",
      "\n",
      "üéôÔ∏è  Ready to record to: c:\\Users\\nicco\\OneDrive\\Documenti\\Obsidian\\daily_notes\\AudioInbox\n",
      "üî¥ Recording started using: System Default (Microphone (2- EDIFIER W830NB))\n",
      "Press SPACE to stop or Ctrl+C to cancel...\n",
      "\n",
      "‚èπÔ∏è  Stopping recording...\n",
      "‚úÖ Recording stopped! Duration: 203.06 seconds\n",
      "‚úÖ Audio saved: voice_note_20250603_173505.wav (17490.0 KB)\n",
      "\n",
      "‚úÖ Recording saved: voice_note_20250603_173505.wav\n",
      "\n",
      "üîÑ Processing voice_note_20250603_173505.wav...\n",
      "\n",
      "==================================================\n",
      "Processing: voice_note_20250603_173505.wav\n",
      "==================================================\n",
      "Transcribing: voice_note_20250603_173505.wav\n",
      "‚úì Audio validation passed: Valid audio file: 203.1s\n",
      "Normalizing audio for optimal transcription...\n",
      "‚úì Audio normalized\n",
      "Starting transcription...\n",
      "Detected language: English\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20305/20305 [01:27<00:00, 232.37frames/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Transcription completed\n",
      "Transcription completed (1519 chars)\n",
      "Available projects: ENPICOM, Saliency\n",
      "Created daily note for project 'Saliency': c:\\Users\\nicco\\OneDrive\\Documenti\\Obsidian\\Vault\\1. Projects\\Daily Notes\\2025-06-03_Saliency.md\n",
      "‚úÖ Success! Note: 2025-06-03_Saliency.md\n",
      "‚úÖ Voice note processed successfully!\n",
      "\n",
      "Choose an option:\n",
      "1. üìÅ Scan for new audio files\n",
      "2. üé§ Record new voice note\n",
      "3. ‚öôÔ∏è  Configure audio device\n",
      "4. üìã Show current settings\n",
      "5. üìÖ Generate timeline\n",
      "6. üö™ Exit\n",
      "\n",
      "üìã Current Settings\n",
      "------------------------------\n",
      "Projects Path: c:\\Users\\nicco\\OneDrive\\Documenti\\Obsidian\\Vault\\1. Projects\n",
      "Audio Inbox: c:\\Users\\nicco\\OneDrive\\Documenti\\Obsidian\\daily_notes\\AudioInbox\n",
      "Daily Notes: c:\\Users\\nicco\\OneDrive\\Documenti\\Obsidian\\Vault\\1. Projects\\Daily Notes\n",
      "Delete after processing: False\n",
      "Audio Device: System Default (Microphone (2- EDIFIER W830NB))\n",
      "Available Projects: ENPICOM, Saliency\n",
      "\n",
      "Choose an option:\n",
      "1. üìÅ Scan for new audio files\n",
      "2. üé§ Record new voice note\n",
      "3. ‚öôÔ∏è  Configure audio device\n",
      "4. üìã Show current settings\n",
      "5. üìÖ Generate timeline\n",
      "6. üö™ Exit\n",
      "üëã Goodbye!\n"
     ]
    }
   ],
   "source": [
    "processor.run_interactive() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa800ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé§ Recording Voice Note\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nüé§ Recording Voice Note\") \n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Test default device first\n",
    "if not processor.audio_recorder.test_default_device():\n",
    "    print(\"‚ö†Ô∏è  Default audio device not available.\")\n",
    "    device_id = processor.audio_recorder.select_device()\n",
    "    processor.audio_recorder.selected_device_id = device_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95738eb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daily_notes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
