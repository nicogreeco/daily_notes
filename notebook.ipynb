{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ab114ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicco\\OneDrive\\Documenti\\Obsidian\\.venv\\Lib\\site-packages\\ctranslate2\\__init__.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "c:\\Users\\nicco\\OneDrive\\Documenti\\Obsidian\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from src.daily_notes_processor import DailyNotesProcessor\n",
    "from src.config import Config\n",
    "from src.audio_processor import AudioProcessor\n",
    "from src.note_generator import NoteGenerator\n",
    "from src.timeline_generator import TimelineGenerator\n",
    "from faster_whisper import WhisperModel, BatchedInferencePipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41965cb",
   "metadata": {},
   "source": [
    "## Step by Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd00ce96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Fast-Whisper model 'turbo'...\n",
      "âœ“ Whisper model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "config = Config('config.yaml')\n",
    "\n",
    "note_generator = NoteGenerator(\n",
    "            config.openai_api_key,\n",
    "            config.config_data['processing']['gpt_model'],\n",
    "            config.config_data['processing']['temperature']\n",
    "        )\n",
    "\n",
    "timeline_generator = TimelineGenerator(\n",
    "            config,\n",
    "            config.openai_api_key,\n",
    "            config.config_data['processing']['gpt_model'],\n",
    "            config.config_data['processing']['temperature']\n",
    "        )\n",
    "\n",
    "audio_processor = AudioProcessor(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36a28f3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('c:/Users/nicco/OneDrive/Documenti/Obsidian/daily_notes/AudioInbox/test_record.m4a')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supported_formats = config.config_data['audio']['supported_formats']\n",
    "audio_files = []\n",
    "\n",
    "for format_ext in supported_formats:\n",
    "    audio_files.extend(config.audio_input_path.glob(f\"*{format_ext}\"))\n",
    "    \n",
    "sorted(audio_files)\n",
    "audio_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25f06a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing: test_record.m4a\n",
      "âœ“ Audio validation passed: Valid audio file: 155.0s\n",
      "Normalizing audio for optimal transcription...\n",
      "âœ“ Audio normalized\n",
      "Starting transcription...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:58<00:00,  9.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Transcription completed\n",
      "Transcription completed (1241 chars)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "audio_path = audio_files[0]\n",
    "\n",
    "# 1. Transcribe audio\n",
    "transcript_data = audio_processor.transcribe(audio_path)\n",
    "print(f\"Transcription completed ({len(transcript_data['text'])} chars)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac1f8eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available projects: ENPICOM, Saliency\n",
      "ChatCompletion(id='chatcmpl-BeFtknkoH2DEpzvmZUkzjzkaKR9Jl', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='```json\\n{\\n  \"project\": \"Saliency\",\\n  \"summary\": \"- Today I worked on my main project, Palency, which I believe is a reference to Saliency.\\\\n- I continued conducting experiments to test the gradient flow on the prediction model over the input embeddings.\\\\n- I focused on debugging an issue from Friday that was causing zero gradient in certain regions of the antibody sequences.\\\\n- The problem was related to how sequences were fragmented by the anarchy sequence segment function.\\\\n- I discovered that some sequences weren\\'t properly segmented, particularly in the framework region 4.\\\\n- This segmentation issue was affecting the indexing and lists, leading to inaccurate results.\\\\n- I made adjustments to make the process resistant to incorrectly fragmented sequences.\\\\n- Despite the fixes, I suspect that some sequences may still not be properly fragmented, leading to noisy output plots.\\\\n- There is a possibility that some CTL regions are being misclassified as framework regions, impacting gradient distribution calculations.\\\\n- Overall, I believe I have resolved the main issue, but I need to implement the solution into the main script for further experiments.\",\\n  \"completed\": \"- Identified and resolved the issue with zero gradient in antibody sequences.\\\\n- Made the segmentation process resistant to incorrectly fragmented sequences.\",\\n  \"blockers\": \"- Some sequences may still not be properly fragmented, which could affect output plots.\\\\n- Need to implement the solution into the main script to run the experiment.\",\\n  \"next_steps\": \"- Correctly implement the segmentation solution into the main script.\\\\n- Continue running experiments to verify the accuracy of the gradient flow calculations.\",\\n  \"thoughts\": \"- I have a feeling that some CTL regions are being misclassified, which may affect the results.\\\\n- Overall, I am 99% confident that the solution will work correctly.\"\\n}\\n```', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1748933932, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_34a54ae93c', usage=CompletionUsage(completion_tokens=371, prompt_tokens=634, total_tokens=1005, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "Created daily note for project 'Saliency': c:\\Users\\nicco\\OneDrive\\Documenti\\Obsidian\\Vault\\1. Projects\\Daily Notes\\2025-06-03_Saliency.md\n",
      "âœ… Success! Note: 2025-06-03_Saliency.md\n"
     ]
    }
   ],
   "source": [
    "# 2. Get available projects\n",
    "available_projects = config.get_available_projects()\n",
    "print(f\"Available projects: {', '.join(available_projects)}\")\n",
    "\n",
    "# 3. Generate daily note with project detection\n",
    "note_path = note_generator.create_daily_note(\n",
    "    transcript_data=transcript_data,\n",
    "    available_projects=available_projects,\n",
    "    audio_filename=audio_path.name,\n",
    "    output_path=config.daily_notes_path\n",
    ")\n",
    "\n",
    "# 4. Delete audio file if configured\n",
    "if config.config_data['audio']['delete_after_processing']:\n",
    "    success = audio_processor.delete_audio_file(audio_path)\n",
    "    if not success:\n",
    "        print(f\"âš  Warning: Could not delete {audio_path.name}\")\n",
    "\n",
    "print(f\"âœ… Success! Note: {note_path.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae77a81",
   "metadata": {},
   "source": [
    "## Interactvie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c8d8e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Whisper model 'medium'...\n",
      "âœ“ Whisper model loaded successfully\n",
      "Setup complete. Drop audio files in: c:\\Users\\nicco\\OneDrive\\Documenti\\Obsidian\\daily_notes\\AudioInbox\n"
     ]
    }
   ],
   "source": [
    "processor = DailyNotesProcessor('config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b07c6dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Daily Notes Processor - Interactive Mode\n",
      "==================================================\n",
      "\n",
      "Choose an option:\n",
      "1. ðŸ“ Scan for new audio files\n",
      "2. ðŸŽ¤ Record new voice note\n",
      "3. âš™ï¸  Configure audio device\n",
      "4. ðŸ“‹ Show current settings\n",
      "5. ðŸ“… Generate timeline\n",
      "6. ðŸšª Exit\n",
      "\n",
      "ðŸŽ¤ Recording Voice Note\n",
      "------------------------------\n",
      "\n",
      "ðŸŽ™ï¸  Ready to record to: c:\\Users\\nicco\\OneDrive\\Documenti\\Obsidian\\daily_notes\\AudioInbox\n",
      "ðŸ”´ Recording started using: System Default (Microphone (2- EDIFIER W830NB))\n",
      "Press SPACE to stop or Ctrl+C to cancel...\n",
      "\n",
      "â¹ï¸  Stopping recording...\n",
      "âœ… Recording stopped! Duration: 245.18 seconds\n",
      "âœ… Audio saved: voice_note_20250603_172430.wav (21118.0 KB)\n",
      "\n",
      "âœ… Recording saved: voice_note_20250603_172430.wav\n",
      "\n",
      "ðŸ”„ Processing voice_note_20250603_172430.wav...\n",
      "\n",
      "==================================================\n",
      "Processing: voice_note_20250603_172430.wav\n",
      "==================================================\n",
      "Transcribing: voice_note_20250603_172430.wav\n",
      "âœ“ Audio validation passed: Valid audio file: 245.2s\n",
      "Normalizing audio for optimal transcription...\n",
      "âœ“ Audio normalized\n",
      "Starting transcription...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicco\\OneDrive\\Documenti\\Obsidian\\.venv\\Lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: English\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24517/24517 [02:40<00:00, 152.40frames/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Transcription completed\n",
      "Transcription completed (2239 chars)\n",
      "Available projects: ENPICOM, Saliency\n",
      "Daily note exists, creating: 2025-06-03_Saliency_173143.md\n",
      "Created daily note for project 'Saliency': c:\\Users\\nicco\\OneDrive\\Documenti\\Obsidian\\Vault\\1. Projects\\Daily Notes\\2025-06-03_Saliency_173143.md\n",
      "âœ… Success! Note: 2025-06-03_Saliency_173143.md\n",
      "âœ… Voice note processed successfully!\n",
      "\n",
      "Choose an option:\n",
      "1. ðŸ“ Scan for new audio files\n",
      "2. ðŸŽ¤ Record new voice note\n",
      "3. âš™ï¸  Configure audio device\n",
      "4. ðŸ“‹ Show current settings\n",
      "5. ðŸ“… Generate timeline\n",
      "6. ðŸšª Exit\n",
      "\n",
      "ðŸŽ¤ Recording Voice Note\n",
      "------------------------------\n",
      "\n",
      "ðŸŽ™ï¸  Ready to record to: c:\\Users\\nicco\\OneDrive\\Documenti\\Obsidian\\daily_notes\\AudioInbox\n",
      "ðŸ”´ Recording started using: System Default (Microphone (2- EDIFIER W830NB))\n",
      "Press SPACE to stop or Ctrl+C to cancel...\n",
      "\n",
      "â¹ï¸  Stopping recording...\n",
      "âœ… Recording stopped! Duration: 203.06 seconds\n",
      "âœ… Audio saved: voice_note_20250603_173505.wav (17490.0 KB)\n",
      "\n",
      "âœ… Recording saved: voice_note_20250603_173505.wav\n",
      "\n",
      "ðŸ”„ Processing voice_note_20250603_173505.wav...\n",
      "\n",
      "==================================================\n",
      "Processing: voice_note_20250603_173505.wav\n",
      "==================================================\n",
      "Transcribing: voice_note_20250603_173505.wav\n",
      "âœ“ Audio validation passed: Valid audio file: 203.1s\n",
      "Normalizing audio for optimal transcription...\n",
      "âœ“ Audio normalized\n",
      "Starting transcription...\n",
      "Detected language: English\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20305/20305 [01:27<00:00, 232.37frames/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Transcription completed\n",
      "Transcription completed (1519 chars)\n",
      "Available projects: ENPICOM, Saliency\n",
      "Created daily note for project 'Saliency': c:\\Users\\nicco\\OneDrive\\Documenti\\Obsidian\\Vault\\1. Projects\\Daily Notes\\2025-06-03_Saliency.md\n",
      "âœ… Success! Note: 2025-06-03_Saliency.md\n",
      "âœ… Voice note processed successfully!\n",
      "\n",
      "Choose an option:\n",
      "1. ðŸ“ Scan for new audio files\n",
      "2. ðŸŽ¤ Record new voice note\n",
      "3. âš™ï¸  Configure audio device\n",
      "4. ðŸ“‹ Show current settings\n",
      "5. ðŸ“… Generate timeline\n",
      "6. ðŸšª Exit\n",
      "\n",
      "ðŸ“‹ Current Settings\n",
      "------------------------------\n",
      "Projects Path: c:\\Users\\nicco\\OneDrive\\Documenti\\Obsidian\\Vault\\1. Projects\n",
      "Audio Inbox: c:\\Users\\nicco\\OneDrive\\Documenti\\Obsidian\\daily_notes\\AudioInbox\n",
      "Daily Notes: c:\\Users\\nicco\\OneDrive\\Documenti\\Obsidian\\Vault\\1. Projects\\Daily Notes\n",
      "Delete after processing: False\n",
      "Audio Device: System Default (Microphone (2- EDIFIER W830NB))\n",
      "Available Projects: ENPICOM, Saliency\n",
      "\n",
      "Choose an option:\n",
      "1. ðŸ“ Scan for new audio files\n",
      "2. ðŸŽ¤ Record new voice note\n",
      "3. âš™ï¸  Configure audio device\n",
      "4. ðŸ“‹ Show current settings\n",
      "5. ðŸ“… Generate timeline\n",
      "6. ðŸšª Exit\n",
      "ðŸ‘‹ Goodbye!\n"
     ]
    }
   ],
   "source": [
    "processor.run_interactive() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa800ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŽ¤ Recording Voice Note\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nðŸŽ¤ Recording Voice Note\") \n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Test default device first\n",
    "if not processor.audio_recorder.test_default_device():\n",
    "    print(\"âš ï¸  Default audio device not available.\")\n",
    "    device_id = processor.audio_recorder.select_device()\n",
    "    processor.audio_recorder.selected_device_id = device_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95738eb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
